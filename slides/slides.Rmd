---
title: "Analyzing time-to-event data with propensity score methods"
author: "Thomas BÃ¸jer Rasmussen"
institute: "Department of Clinical Epidemiology<br>Aarhus University Hospital"
date: "2020-11-30"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "my-css.css"]
    seal: true # Automatic title slide from YAML
    nature:
      self_contained: false
      ratio: '16:9' # Display ratio (default 4:3)
---      

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  dev = "svglite",
  dev.args = list(bg="transparent"),
  fig.width = 9, 
  fig.height = 4
)

library("here")
library("data.table")
library("devtools")
library("dplyr")
library("ggdag")
library("ggplot2")
library("ggridges")
library("glue")
library("gt")
library("gtsummary")
library("patchwork")
library("showtext")
library("svglite")
library("tidyr")
library("RefManageR")

# Modified Cite function where options are set and brackets are removed
cite_mod <- function(...) {
  gsub(
    "\\[|\\]", "", 
    Cite(bib = my_bib, before = "<sup>", after = "</sup>", ...)
  )
}

# Discrete colourblind-friendly palette
cvd_colours <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00")

# ggplot theme options to make background transparent.
theme_trans <- theme(
  panel.background = element_rect(fill = "transparent", colour = NA),
  plot.background = element_rect(fill = "transparent", colour = NA),
  legend.background = element_rect(fill = "transparent", colour = NA),
  legend.key = element_rect(fill = "transparent", colour = NA),
  strip.background = element_rect(fill = "transparent", colour = NA),
)

# Load and prepare data

# absolute_effect_estimates
absolute_effect_estimates <- fread(
    here("data", "absolute_effect_estimates.csv")
  )
  
# analysis_dat
analysis_dat <- fread(here("data", "analysis_dat.csv")) %>%
  rename(match = `__match`)
 
# assess_ph
assess_ph <- fread(here("data", "assess_ph.csv")) %>%
  filter(!is.na(log_time))

# cumulative_incidences
cumulative_incidences <- fread(here("data", "cumulative_incidences.csv"))

# emperical_cdf
empirical_cdf <- fread(here("data", "empirical_cdf.csv")) %>%
  rename(variable = `__variable`, x = `__x`, cdf = `__cdf`) %>%
  mutate(
    strata_male = case_when(
      is.na(male) ~ "Overall",
      male == 0 ~ "Female",
      male == 1 ~ "Male",
    )
  )  %>%
  select(-c("strata", "male"))

# induced_absolute_effects
induced_absolute_effects <- fread(
    here("data", "induced_absolute_effects.csv")
  )  %>%
  mutate(risk_diff = round(risk_diff, 3))

# induced_relative_effects 
induced_relative_effects <- fread(
    here("data", "induced_relative_effects.csv")
  )

# population 
population <- fread(here("data", "population.csv")) 

# relative_effect_estimates
relative_effect_estimates <- fread(
    here("data", "relative_effect_estimates.csv")
  ) %>%
  mutate(
    hr_ci = paste0(
      formatC(HazardRatio, format = "f", digits = 3),
      " (", 
      formatC(HRLowerCL, format = "f", digits = 3), 
      " - ",
      formatC(HRUpperCL, format = "f", digits = 3),
      ")"
    )
  )
  
# standardized_differences
standardized_differences <- fread(
  here("data", "standardized_differences.csv")
  ) %>%
  rename(var = `__var`, sd = `__sd`) %>%
  mutate(
    strata_male = case_when(
      is.na(male)  ~ "Overall",
      male == 0 ~ "Female",
      male == 1 ~ "Male"
    )
  )  %>%
  select(-c("strata", "male"))

# summary_tbl
summary_tbl <- fread(here("data", "summary_tbl.csv")) %>%
  rename(label = `__label`, stat = `__stat_char`) %>%
  mutate(
    stat = ifelse(is.na(stat), "", stat),
    pop = case_when(
      pop == "ATE-weighted" ~ "ate",
      pop == "Original" ~ "pop",
      pop == "ATT-weighted" ~ "att",
      pop == "Matched" ~ "matched"
    )
  ) %>%
  pivot_wider(names_from = c(pop, treatment), values_from = stat)  %>%
  mutate(
    label = case_when(
      label == "__n" ~ "Number of patients, N (%)",
      label == "male" ~ "Male, N (%)",
      label == "age" ~ "Age, median (Q1;Q3)",
      label == "comorbidity_score: title" ~ "Comorbidity score, N (%)",
      label == "comorbidity_score: 0" ~ "  0",
      label == "comorbidity_score: 1-2" ~ "  1-2",
      label == "comorbidity_score: 3+" ~ "  3+",
      label == "risk_score: title" ~ "Risk score, N (%)",
      label == "risk_score: 0" ~ "  0",
      label == "risk_score: 1" ~ "  1",
      TRUE ~ as.character(label)
    )
  )

# weight_stats
weight_stats <- fread(here("data", "weight_stats.csv"))

# bootstrap_est
bootstrap_est <- fread(here("data", "bootstrap_est.csv")) %>%
  rename_all(tolower) %>%
  select(pop, replicate, hazardratio)

```

```{r load-refs, include=FALSE}
BibOptions(
  check.entries = FALSE,
  bib.style = "numeric",
  cite.style = "numeric",
  style = "text",
  use.regex = TRUE,
  ignore.case = TRUE,
  hyperlink = FALSE,
  dashed = FALSE
)
my_bib <- ReadBib("./bibliography.bib", check = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_light(base_color = "#23395b")
```

```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view"))
```

## Slide notes

Made with `xaringan` package in R.

Source: [https://github.com/thomas-rasmussen/ps-webinar]()

Slides: 

- Link to slides: [https://thomas-rasmussen.github.io/ps-webinar/slides/slides.html]()

- Press "p" to toggle presenter notes on/off

- Press "o" to toggle tile overview on/off

- Press "h" to see all keyboard shortcuts

???

Quick notes on the slides: they are made with the `xaringan` package in R, which is an R Markdown extension based on the remark.js JavaScript library. Furthermore, the slides are hosted directly from the GitHub repository using GitHub Pages.

Note that you can press "p" to toggle presenter notes on/off, and "o" to see a tile overview of all the slides.

---

## Running example

```{r dag}

coords <- list(
  x = c(
    treatment = 0,
    male = 1, age = 1,
    risk_score = 1.5,
    comorbidity_score = 1,
    death = 2
  ),
  y = c(
    treatment = 0,
    male = 1,
    age = 2,
    risk_score = 3,
    comorbidity_score = 3,
    death = 0
  )
)

labels <- list(
  treatment = "Treatment", 
  male = "Sex", 
  age = "Age", 
  risk_score = "Risk score", 
  comorbidity_score = "Comorbidity score", 
  death = "All-cause mortality"
)

dag <- dagify(
  death ~ treatment + risk_score + age + male + comorbidity_score,
  treatment ~ age + male + comorbidity_score,
  labels = labels,
  coords = coords
)

ggdag(dag, node = TRUE, text = FALSE, use_labels = "label") +
  theme_dag() +
  theme_trans 

```

???

The presentation is structured around a running example using simulated data. At the end of the presentation we will look at how this was implemented in SAS, and what SAS-macros were used to help facilitate the analyses.

For our running example we imagine we have some population of patients with a particular disease, that might or might not get treated after being diagnosed. The efficacy of the treatment to lower 1-year all-cause mortality is not well-established, so we want to conduct a new, and hopefully better, study where we investigating whether or not this is the case.

We start out by trying to establish our causal assumptions using a DAG. Based on a priori knowledge we will assume that age, sex, and existing comorbidities influences both the treatment and all-cause mortality. We will summarize existing comorbidities in a comorbidity score, eg the Charlson Comorbidity Index. Furthermore, we know that some established risk score is a risk factor for all-cause mortality, but we are somewhat certain that it does not affect treatment. Finally, we also assume that there is interaction between age and sex, but we can't incorporate this assumption in a DAG.

---

## Study designs

- Randomized controlled trials (RCT)

  - Pros: gold standard, no unmeasured confounding
  
  - Cons: often infeasible, unethical and/or expensive 

- Observational studies:

  - Pros: fast and cheap compared to a RCT
  
  - Cons: unmeasured confounding
  

Propensity score (PS) methods can be used to mimic RCT

???

So what general types of study designs can we use to test our hypothesis that the treatment does actually lowers all-cause mortality?

A RCT is considered the gold standard. In a RCT we would randomly allocate the treatment or a placebo to patients. Because of this randomization of the treatment, the multivariate distribution of patient characteristics would be similar in both treatment groups, and we would not have to worry about confounding; we could simply compare the number of deaths in each treatment group. Unfortunately RCT's are often infeasible, unethical and/or expensive.

On the other hand we could conduct an observational study. Lets assume that the treatment has been used in practice for some time, and we know we can collect data on treatment, covariates and the outcome from registries at our disposal. Doing this would probably be faster and cheaper than conducting a RCT. Although, since treatment is not given at random in practice, there will probably be systematic differences in patients characteristics between the treatment groups that we need to take into account in our analysis. Furthermore, we can usually only account for *observed* confounding, and we will have to argue about the reasonability of our causal assumptions ensuring that there is no unmeasured confounding.

Ideally we would do a RCT, but since that is not possible we will instead imagine that we choose to conduct an observational study. So how are we going to handle the confounding we assume will be present according to our causal assumptions? In this presentation we will introduce propensity score methods as a way of imitating an RCT, in the sense that we create a matched or weighted pseudo-population using the the so-called propensity score, in which there is no observed confounding, ie the pseudo-population will look like it is from an RCT. We can then directly compare outcomes in this pseudo-population as we would in an RCT.

---

## Excerpt of simulated data

```{r dat-excerpt}

population %>%
  slice(1:10) %>%
  gt()

```

???

So lets imagine we collect the needed information on a population of `r format(nrow(population), big.mark = ",")` patients with the diagnosis. We want to treat the outcome as a time-to-event outcome, and we are interested in 1-year all-mortality, so we collect data on time-to-death and censor patients after 1-year of follow-up if they have not yet died. Because we have super-registries in our imaginative example, we actually don't have other sources of censoring.

Here we show an excerpt of our cleaned data. 

- id: patient ID

- treatment: 0 = No, 1 = Yes 

- male: 0 = female, 1 = male, 

- age: age at diagnosis

- risk_score: Risk score at diagnosis. 0 or 1.

- comorbidity score at diagnosis. 0, 1-2 or 3+.

- time: Days of follow-up after diagnosis.

- death: Event indicator at the the end of follow-up. 0 if patient censored after 365 days, 1 if patient died at end of follow-up.

---

## Descriptive summary

```{r dat-summary}

summary_tbl %>%
  select(c(label, pop_0, pop_1)) %>% 
  gt(rowname_col = "label") %>%
  cols_label(
    pop_0 = "Untreated",
    pop_1 = "Treated"
  )

```

???

To get a first impression of the data we have collected, we make a descriptive summary of patient characteristics in our population. We see that about half of the patients get the treatment, and that there are differences in the distribution of several patients characteristics, namely all of our assumed confounders. As we had also assumed, it does not look like the risk score is affecting treatment, at least not when we look at the marginal distribution of the risk score.

What we want to do is to use PS methods to make a new matched/weighted pseudo population, where there is no imbalance in the distribution of confounders, and then estimate the treatment effect directly in that population.

---

## The potential outcomes framework

Treatment indicator $Z$:

- $Z=0$: untreated
  
- $Z=1$: treated

Pair of potential outcomes:

- (time-to-event, event) under no treatment: $Y_0 = (T_0, D_0)$
  
- (time-to-event, event) under treatment: $Y_1 = (T_1, D_1)$

Observed (time-to-event, event): $Y = ZY_1 + (1-Z)Y_0$

???

Before we go on we need to introduce some concepts that can be used to conceptualize both the PS and RCT methodology.

First, we introduce the potential outcomes framework.

Assume we have two possible treatments. Each subject has a pair of potential outcomes; the outcome under no treatment $Y_0 = (T_0, D_0)$, and the outcome under treatment $Y_1 = (T_1, D_1)$. Here, $T_z$ is the time-to-event under treatment $Z=z$, and $D_z$ the event indicator. Only one of the potential outcomes is observed; the outcome corresponding to the actual treatment received. The other outcome is a potential/unobserved outcome: the outcome that would have happened had the subject been given the other treatment.

We can imagine the observed outcome as a combination of the two potential outcomes $Y = ZY_1 + (1-Z)Y_0$ (maybe with some slight abuse of notation here, as we are working with time-to-event outcomes).

---

## The potential outcomes framework

```{r potential-outcomes}

population %>%
  mutate(
    time_0 = ifelse(treatment == 0, time, NA),
    death_0 = ifelse(treatment == 0, death, NA),
    time_1 = ifelse(treatment == 1, time, NA),
    death_1 = ifelse(treatment == 1, death, NA)
  ) %>% 
  slice(1:10) %>%
  gt()

```

???

We can try to illustrate this in our example data, by adding columns with information on potential outcomes. As we can see, we only observe the potential outcome under the treatment that was actually received, while we have missing information on the potential outcome under the treatment that was not observed.

Lets imagine that we did actually have data on all potential outcomes for each patient. How would we actually define "the treatment effect"? 

---

## Average treatment effect (ATE)

Continuous and dichotomous outcomes: 

- Treatment effect: $Y_1 - Y_0$ (or $Y_1 / Y_0$)

- Average treatment effect (ATE): $E[Y_1 - Y_0]$ ( $E[Y_1/Y_0]$ )

Time-to-event outcome:

- Absolute ATE - Risk difference at time $t$: $F_{Y_1}(t) - F_{Y_0}(t)$

- Relative ATE - Hazard ratio at time $t$: $\lambda_{Y_1}(t) / \lambda_{Y_0}(t)$

???

If we start out by imagining we have a dichotomous or continuous outcome,
it would be natural to define the treatment effect as $Y_1 - Y_0$, ie as the difference in potential outcomes. If a relative effect is of interest the treatment effect could also be defined as eg $Y_1 / Y_0$.

The average treatment effect (ATE) would then be defined as $E[Y_1 - Y_0]$ (or $E[Y_1 / Y_0]$): the average effect of moving an entire population from untreated to treated (at the same time).

This definition makes a lot of sense for continuous and dichotomous outcomes, but for time-to-event outcomes, these definitions are not that meaningful. Even if we had no censoring, the ATE would be a mean difference/ratio of time-to-events, which is usually not of interest. On top of that, we need to be able to handle the incomplete nature of our outcome data. 

A better definition of the ATE would be as the absolute difference in risk of the outcome within a specified duration of follow-up time $t$: $F_{Y_1}(t) - F_{Y_0}(t)$, or as the relative effect of treatment on the hazard of the outcome $\lambda_{Y_1}(t) / \lambda_{Y_0}(t)$. So we will define the absolute/relative ATE as such. 

We can imagine we have two potentially observable survival curves, one that would have been observed had all patients gotten the treatment, and one that would have been observed had all patient not gotten the treatment. We would then compare these potential curves by either estimating the absolute risk difference at some time-point, or by pooling the two sets of potential outcomes and regress the hazard of the outcome on an indicator variable denoting treatment status. 

---

## Estimate treatment effect in RCT

Randomization $=> F_{Y_i}(t) \leftarrow F_{Y|Z = i}(t)$

All-cause mortality $=>$ no competing risks $=> F(t) = 1- S(t)$, estimate S(t) with Kaplan-Meier estimator.

Estimate relative hazard using Cox regression.

???

So how would we estimate the ATE in a RCT? In that case, the treatment would have been randomly allocated, so we can estimate the risk at time $t$ had everybody gotten a certain treatment, by simply using the patients who actually got that treatment. Note that our outcome of interest is all-cause mortality, so $F(t) = 1- S(t)$, and we can simply estimate $S(t)$ using the Kaplan-Meier estimator.

To estimate the hazard ratio, we would pool the observations and use crude Cox regression using the treatment indicator as the only independent variable.

---

## Estimate treatment effect in RCT

```{r analysis-rct}

dat1 <- cumulative_incidences %>%
  filter(pop == "Original") %>% 
  mutate(
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated"))
  )

risk_diff_1y <- absolute_effect_estimates %>%
  filter(time == 365 & pop == "Original") %>%
  mutate(risk_diff_pct = round(100 * cum_inc_diff, 1)) %>%
  pull(risk_diff_pct) %>% formatC(format = "f", digits = 3)

mar_hr <- relative_effect_estimates %>%
  filter(pop == "Original" & effect == "Marginal" & var_est == "sandwich") %>%
  pull(hr_ci)

dat1 %>%
  ggplot(aes(time, cum_inc, group = treatment, colour = treatment)) +
  geom_step() +
  theme_classic() +
  scale_colour_manual(values = cvd_colours) +
  scale_x_continuous(expand = c(0, 10), breaks = c(0, 100, 200, 300, 365)) +
  scale_y_continuous(expand = c(0, 0), labels = scales::percent) +
  labs(
    x = "Days since diagnosis",
    y = "All-cause mortality risk",
    group = NULL,
    colour = NULL
  ) +
  theme(legend.position = c(0.9, 0.2)) +
  theme_trans +
  annotate(
    "text", label = glue("1-year risk difference =  {risk_diff_1y}%"), 
    x = 10, y = 0.7, hjust = 0, vjust = 1
  ) +
  annotate(
    "text", label = glue("HR = {mar_hr}"), 
    x = 10, y = 0.6, hjust = 0, vjust = -1
  )

```

???

Going back to our example, lets pretend its from a RCT for a moment, and estimate the absolute and relative ATE one year after diagnosis.

We see that the cumulative incidence curves are more or less identical and that there does not seem to be any treatment effect on either scale.

Our data is not from an RCT though. We would like to be able to do the analyses analogously to how we would analyze a RCT as we just did, and we will get back to how we can do this using PS methods. But before we move on to define what a propensity score is and how we can use them, we need to introduce some additional concepts.

---

## Average treatment effect in the treated (ATT)

- Average treatment effect among patient who got the treatment (ATT):

$$E[Y_1 - Y_0 | Z = 1]$$

- RCT: ATE = ATT

- Observational study: ATE $\neq$ ATT.

???

A related measure of effect is the average treatment effect in the treated (ATT): $E[Y_1 - Y_0 | Z = 1]$.

In our modified ATE definitions for time-to-event outcomes, we can again imagine we have two potentially observable survival curves, now just restricted to potential outcomes for patients who actually got the treatment.

In a RCT, the ATE and ATT is the same, since we are randomly allocating the treatment. The population of treated patients is a random subset of the whole population, so the treatment effect will be the same in either, ie the ATE and ATT is the same. But this is not generally the case in observational studies, where different mechanisms determine whether or not treatment is given or withheld. There is no reason to expect that the ATE and the ATT will coincide in an observational study. It might be, for example, that the treatment is more likely to be given to patients who will benefit from the treatment, and more likely to be withheld from patients who will not benefit from it. If this is the case, the ATT would probably show a greater beneficial effect than the ATE, since the ATE is trying to estimate the average effect among a larger group of people where the treatment effect is less beneficial on average.

Since PS methods can be used to estimate both the ATT and the ATE, it is important to distinguish between the two.

---

## ATE or ATT?

Estimate ATE or ATT? Depends on study question.

- Treatment is "new drug" versus "old drug": probably ATE

- Pregnant women with depression,  treatment is antidepressants: probably ATT

???

So should we estimate the ATE or the ATT in an observational study? It depends on the study question of interest.

Lets imagine that our treatment is a "new drug" versus "old drug" scenario. In this case we are often interested in knowing if the new drug is better than the old drug and should replace it as the treatment of choice. If this is the case we want to estimate the ATE, since the ATE is the average effect of switching everybody from the old drug to the new drug at the same time.

Now lets instead imagine a more specific example where we have a population of pregnant women with depression, and the treatment is antidepressants versus no treatment. In general, we do not want to give drugs to pregnant women unnecessarily, so we are probably not interested in whether or not we should give all depressed women antidepressants. We are likely more interested in the effect of antidepressants among the women who do actually get them. In that case the ATT is what we are interested in.

---

## Marginal and conditional effects

- Conditional effect: average effect on "individual" level

- Marginal effect: average effect on population level

- Non-collapsible effect estimator: marginal effect $\neq$ conditional effect

- The hazard ratio and odds-ratio are non-collapsible.

- RCT/PS-analysis and regression effect estimates often not directly comparable!

???

Another complication that we need to consider is the concept of marginal and conditional effects. 

A conditional effect is the average effect at the "individual" level (defined by the covariates conditioned on), of changing a patient's treatment status from untreated to treated. We often attain an estimate of a conditional effect by "smoothing" the effect across patients. This is what happens when we fit a regression model where we condition on confounders.

A marginal effect is the average effect at the population level, of changing the treatment status of the entire population at the same time. This is what we are estimating with the ATE/ATT in a RCT (and ps-analysis). We are directly comparing two populations that are equal, except in their treatment. This gives an estimate of the marginal effect.

Intuitively, you might expect the marginal and the conditional effect to be the same. Unfortunately whether or not this is the case depends on the effect estimator. By definition, a collapsible effect estimator is an effect estimator for which the marginal and conditional effect coincide. The mean difference and risk difference are examples of collapsible effect estimators. Non-collapsible effect estimators are effect estimators for which the marginal and conditional effect does not coincide. The hazard-ratio and odds-ratio effect estimators are examples of non-collapsible effect estimators. The direction of the marginal and conditional effect is the same for non-collapsible effect estimators, but as the true effect becomes more extreme, the difference in the effects will also be more extreme. If the true effect is a null effect, the marginal and conditional effect will still coincide as a null effect.

We will not go into more details about this confusing complication, but it is important to realize that this nuance exist. In observational research we often use non-collapsible effect estimators, eg hazard-ratios in Cox regression and odds-ratios in logistic regression. We need to be aware that we can not directly compare effect estimates from such models with hazard-ratio and odds-ratio effect estimates from RCT's, because we are not estimating the same same type of effect!

---

## Propensity scores

The propensity score (PS) is the conditional probability of treatment $Z$, given variables $X$:

$$PS = P(Z = 1 | X)$$

The PS is a balancing score, ie

$$X \perp Z | PS$$

???

Having defined all these concepts, we now move on to introduce propensity scores.

The propensity score is the conditional probability of treatment $Z$, given variables $X$.

The PS is a so-called balancing score, ie given $PS$, $X$ and $Z$ are independent. This means that among patients with the same $PS$, the multivariate distribution of $X$ is expected to be the same for both treated and untreated patients.

Using this property one can show, that if we use our confounders as $X$, calculate the estimated $PS$, denoted $ps$, and then compare treated and untreated patients with the same estimated propensity score, the distribution of the confounders are expected to be the same.

---

## Estimation of propensity scores

- True propensity score almost always unknown in observational studies.

- Typically estimated using logistic regression

- Include all (potential) confounders and predictors of outcome in PS model

- Exclude strong predictors of the exposure from the PS model

- We do not care about goodness-of-fit tests or discrimination/calibration of the model. We only care about balancing our confounders.

???

Before we introduce the different methods using the balancing score property of the propensity score, lets talk about how we can estimate $PS$. 

In a standard RCT, treatment is decided by chance, so the true $PS$ is 0.5. But in an observational study, the mechanisms leading to treatment is unknown, so we do not know the true $PS$. We have to estimate them instead.

Estimation of PS's is usually done using logistic regression. We want to balance the distribution of our confounders, so we need to include all our confounders in our PS model, or we will get a biased estimate of the treatment effect. Furthermore, we should include all predictors/risk-factors of the outcome. This will correct for chance imbalances of the predictor and can reduce the variance of the estimate of treatment effect. On the other hand, we should not include strong predictors of the exposure in the PS model, since we do not need to balance them and they can increase the variance of the treatment effect estimate.

So how do we evaluate our PS model? Normally we would look at goodness-of-fit tests, or the calibration of the model and how well it discriminates. But this is inappropriate in this context. The only thing we care about is balancing the distribution of our confounders, everything else is irrelevant.

We will get back to how to assess covariate balance later.

---

## Estimation of propensity scores

Running example:

  - Add all confounders and risk score in PS model
  
  - Add age as a restricted natural cupic spline
  
???

So in our running example, we would include our confounders and our predictor of the outcome into the PS model, namely the variables age, sex, comorbidity score, and risk score. Age is a continuous variable and we will use a restricted cubic spline to estimate the correct functional form. We also include an interaction term of age and sex since we assume that there is age and sex interaction.
---

## Propensity score methods

Broadly speaking:

  - PS stratification

  - PS adjustment

  - PS matching

  - PS weighting

???

Broadly speaking there are 4 approaches to using the balancing score property of the propensity score to handle confounding.

We will not talk about PS stratification and PS adjustment in this presentation. They are, again broadly speaking, the traditionally used PS methods, but both of the approaches can be problematic for different reasons we will not delve into here.

We will instead focus on PS matching and PS weighting.

---

## PS matching

- Usually 1:1 matching untreated to treated patients

- Permits estimation of the ATT

- One reasonable way to do the matching:

  - Nearest neighbor matching
  
  - Match on $logit(ps)$
  
  - Use caliper of 0.2 times the standard deviation of $logit(ps)$
  
  - Match with replacement

???

PS matching entails forming matched sets of treated and untreated patient who have similar $ps$'s. Individual patients with the same $ps$ might not have the exact same confounder values, but the *distribution* of the values is expected to be similar. So intuitively we can see that PS matching would result in a matched population where the distribution of confounders are similar for treated and untreated patients.

PS matching can be done in many different ways, but 1:1 matching untreated to treated patients is the usual approach. This permits estimation of the ATT, since we are creating a matched population where we have paired each treated patient with an untreated patient that represents an estimate of the unobserved potential outcome for the treated patient.

1:1 matching can be done in many different ways, but a reasonable approach is:

- Nearest neighbor matching: We use the untreated patient with the $ps$ closest to the treated patient's $ps$ as the match.

- Match on $logit(ps)$: The reason for this is technical so we won't go into details here, but doing this has been shown to have advantages in some scenarios.

- Use a caliper: We should not only use the nearest neighbor as the match, we should also have a limit on how much of an absolute difference in $ps$'s we will tolerate when finding a match, since there is no guarantee we can find a proper match. A caliper equal to 0.2 times the standard deviation of $logit(ps)$ is commonly used, since it has been shown to work well in simulation studies.

- Match with replacement: Matching without replacement is commonly used, but doing so requires us to have a vast pool of potential controls relative to the number of treated patients, or we won't be able to find suitable matches for all treated patients. Matching with replacement usually overcomes this issue. It does complicate estimation of a confidence interval for the treatment effect since we no longer have independent observations, but as we shall see later this is actually also the case when matching without replacement and when doing PS weighting, and we can handle this complication.

Making a matched population is not trivial in practice, and is often done in horribly inefficient ways. In the SAS example we will use a very efficient macro to facilitate this process.

---

## PS matched population

```{r dat-match}

analysis_dat %>%
  filter(pop == "Matched") %>%
  select(-c("pop", "w")) %>% 
  relocate(match) %>%
  arrange(match, desc(treatment)) %>%
  slice(1:10) %>%
  gt() %>%
  tab_header("Matched population")
  
```

???

Here we can see an excerpt of a PS matched population using the above-mentioned SAS macro.

We can see that, as expected, that just because a treated and untreated patient has almost identical ps's, that does not mean that they have equal confounder values.

---

## PS weighting

- Use $ps$ to create weighted pseudo-population where $X \perp Z$

  - ATE weights: $\frac{Z}{ps} +\frac{1-Z}{1-ps}$

  - ATT weights: $Z + (1-Z)\frac{ps}{1-ps}$

???

PS weighting uses weights based on the $ps$ to create pseudo-populations where $X \perp Z$. 

Using the ATE weights, both the treated and untreated patients are weighted so that their confounder distribution match that of the combined population. Using ATE weights creates a pseudo population that is approximately twice as big as the original population, where we have estimated what the potential outcomes would have been had everyone been treated,and if no one had been treated. This permits estimation of the ATE.

The ATE weights are also called Inverse Probability of Treatment (IPTW) weights, because we weight a patient with the inverse of the probability of the treatment they received. 

Using the ATT weights, the untreated patients are weighted so that their confounder distribution matches that of the treated population. Using ATT weights creates a pseudo population of approximately twice the size of the number of treated patients, where we reweight the untreated patients so they can be used as estimates of what would have happened if the treated patients would have not been treated, which permits estimation of the ATT.

---

## PS weighting examples 

- Only include sex in PS model

- 50% untreated and treated patients

- 50% untreated and 50% treated males

$ps$ = 0.5 for all patients

ATE weights: $\frac{Z}{ps} +\frac{1-Z}{1-ps} = \frac{Z}{0.5} +\frac{1-Z}{1-0.5} = 2$

ATT weights: $Z + (1-Z)\frac{0.5}{1-0.5} = 1$

???

Lets imagine we only include sex in the PS model, and that we have 50% males among both the untreated and treated patients, and that we have 50% treated and untreated patients. The combined population will then also have 50% males, and we don't actually need to balance anything, we just need to upweight our treated and untreated patients so that each population is the same size as the combined population. Our PS model would give everyone a $ps$ of 0.5, since there's a 50% chance of being treated no matter what sex you are, and we can see that all patients would receive a weight of 2, resulting in a weighted population twice as big, where the sex distribution is unchanged, as it should be, and the treated and untreated populations are now twice as big, making both of them the same size as the combined population, which is also what we wanted.

If we look at the ATT weights, we can see that this simple example would give both treated and untreated patients a weight of one, since the sex distribution is already balanced, and the untreated population is already the same size as the treated population.

---

## PS weighting examples 

- Only include sex in PS model

- 50% untreated and treated patients

- 30% untreated and 70% treated males (as in running example)

$ps = 0.7$ for men and $ps = 0.3$ for females

ATE weights:

- Treated males: 1.43
- Treated females: 3.33
- Untreated males: 3.33
- Untreated females: 1.43

ATT weights:

- Untreated males: 2.33
- Untreated females: 0.43

???

If we now imagine that there are 70% treated males and 30% untreated males, but there is still 50% treated and untreated patients, as in our running example.
The $ps$ is now 0.7 for males and 0.3 for females. The combined population still has 50% males, so we need to downweight treated males and upweight treated females, to make that population look like the combined population. For the untreated population its the reverse. Men are underrepresented so we need to give them larger weights than untreated females to get a sex distribution that mirrors that of the combined population. This is reflected in the ATE weights, since treated males are going to have a weight of 1.43 and females will have a weight of 3.33 which is way bigger than 1.43 effectively downweighting treated men. Reversely, untreated men will have a weight of 3.33 and untreated women a weight of 1.43, effectively downweighting untreated females.

For the ATT weights, treated patients will still have a weight of one, but we can see that untreated males will have a weight of 2.33 and untreated females will have a weight of 0.43, both upweighting untreated men, and downweighting untreated females at the same time.

---

## ATE-weighted population

```{r dat-ate-weight}

analysis_dat %>%
  filter(pop == "ATE-weighted") %>%
  select(-c("pop", "match")) %>%
  rename(ate_weight = w) %>%
  slice(1:10) %>%
  gt() %>%
  tab_header("ATE-weighted population")

```

???

We can easily create the weighted populations by simply calculating the ATE and ATT weights for each patient. Here is an excerpt of ATE weighted population.

Since our PS model is relatively complicated it is not straight forward to understand the weights, but we can see that patient 4 has a high weight, which is probably strongly related to the fact that it is a treated female as in our simplified example.

---


## ATT-weighted population

```{r dat-att-weight}

analysis_dat %>%
  filter(pop == "ATT-weighted") %>%
  select(-c("pop", "match")) %>%
  rename(att_weight = w) %>%
  slice(1:10) %>%
  gt() %>%
  tab_header("ATT-weighted population")

```

???

Excerpt of the ATT-weighted population. Note that all treated patients have a weight of 1. We see many untreated females with low weights, which is to be expected since the females are way more predominant among the untreated compared to the treated, so we need to downweight them so match the sex distribution among the treated.

---

## Overlap in PS-distributions 

- Feasibility of using PS methods should be considered

- Need sufficient overlap of $ps$ distribution for treated and untreated patients

???

We have now introduced PS matching and PS weighting, but we should consider whether or not such analyses are even feasible.

For PS matching we need to find untreated patients with $ps$'s similar to the treated patient's, so if the distribution of $ps$ for the untreated does not cover the distribution of $ps$ for the treated, we might not be able to find suitable matches. Likewise, re-weighting one $ps$ distribution to another requires overlap of these distributions.

So we can assess the feasibility of a PS analysis by simply looking at the overlap in the distribution of $ps$ for treated and untreated patients. We should do this before anything else, since it might be immediately clear that a PS analysis won't work.

---

## Overlap in PS-distriubtions

```{r ps-overlap}

analysis_dat %>%
  filter(pop == "Original") %>% 
  mutate(
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated"))
  ) %>%   
  ggplot(aes(ps, fill = treatment, group = treatment)) +
  geom_density(alpha = 0.5, bw = 0.01) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(
    title = NULL,
    fill = NULL,
    group = NULL,
    y = NULL
  ) +
  scale_fill_manual(values = cvd_colours) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    legend.position = c(0.9, 0.9),
    panel.spacing = unit(1.5, "lines")
  ) +
  theme_trans +
  coord_cartesian(xlim = c(-0.05, 1.05), ylim = c(0, 4))

```

???

Returning to our example, we try plotting the $ps$ distribution for both the treated and untreated patients. We see that the distributions are far from similar, but there seems to be a sufficient overlap, even for small and large values of $ps$. We can see there might be some minor non-overlapping in the extreme ends of the distributions, but we do not think this will be a problem. 

---

## PS analysis assumptions

- Consistency

- Conditional exchangeability

- SUTVA

- Positivity

- Any additional model assumptions

???

At this point we have used different PS methods to obtain new populations where we can directly compare outcomes as in a RCT to estimate the ATE and ATT. We have also looked at the $ps$ distribution to check that the PS analyses are feasible. Furthermore, we should be aware of what assumptions we are making in a PS analysis, and try to assess whether or not these assumptions are violated.

---

## Consistency

Consistency: $Z = z => Y = Y_{z}$

Untestable

???

Consistency holds if the observed outcome $Y$ is equal to the  counterfactual/potential outcome $Y_{z}$ for patients with treatment $Z=z$, ie the potential outcome under the treatment that is actually received is the outcome we observe.

On an intuitive level this makes sense. If a patient is treated, we have to assume that we are observing the outcome under treatment. 

The assumption is untestable.

In our example lets assume the treatment is taking a drug. Then we are assuming that the patient is *actually* taking the drug. If not, the outcome we are actually observing is not the outcome under treatment, but the outcome under no treatment.

---

## No unmeasured confounding

We are assuming we have no unmeasured confounding

Untestable

???

We are assuming that we have no unmeasured confounding. If we have unmeasured confounders, they will not be balanced after ps-matching or weighting, and thus an unbiased estimate of the treatment effect will not be possible.

---

## Stable Unit Treatment Value Assumption (SUTVA)

No interference between subjects

Untestable

???

SUTVA is the assumption that there is no interference between subjects, ie that the counterfactual outcome under treatment for one subject does not depend on the other subjects' treatment values. 

This assumption is also untestable.

Imagine a study where that one patient under treatment died, and other patients who were treated found out, and as a result got so worried that they died from stress themselves, then SUTVA would be violated.

---

## Positivity

Positivity: $0<PS<1$

Extreme weights in PS weighting and exclusion of treated patients in PS matching indicates violation of this assumption.

???

The positivity assumption is the assumption that there is a non-zero probability of both treatments for all patients.

This assumption is also intuitively reasonable. If some patients have characteristics causing them to always/never be treated, we can not find comparable patients with the other treatment that can be used to estimate "what would have happened had the patient been given the other treatment".

If a lot of treated patients have been excluded from a matched population or we have extreme weights in our weighted populations, this indicates that we have a problems with the positivity assumption.

We will talk more about this later in the presentation.

---

## Model assumptions

- Additional outcome model assumptions has to be fulfilled

- Correct PS model specification is sufficient but not actually necessary!

???

If any outcome model is specified, we need to assess all additional assumptions we are making in that model.

For example, if we do Cox regression then we need to assess the proportional hazard assumption, and assume that we have independent censoring.

Correct specification of the PS model ensures balance of the multivariate distribution of (observed) confounders. Strictly speaking this assumption is only sufficient, it is not a necessary assumption. If we can achieve balance in all confounders, we do not care whether or not the PS model is correctly specified!

---

## Balance assessment

- Assess covariate balance after matching/weighting, but before comparing outcomes

- If insufficient balance:

  - Fine-tune PS model 

  - review population exclusion/inclusion criterias

- Repeat until balance!

- Possible to separate design and analysis of study as in an RCT!

???

We have created our matched/weighted population, the PS analysis seem feasible since we sufficient overlap in the $ps$ distributions, and we are aware of the assumptions we are making. Before we estimate the treatment effect, we also need to assess whether or not we have actually achieved covariate balance as we mentioned earlier. If we find that we have insufficient covariate balance, we should take steps to improve the balance before moving on to estimating the treatment effect.

Insufficient balance might be a result of the PS model not being sufficiently complex. This might be remedied by including continuous variables as splines, adding interaction terms etc.

Another problem can be that the treatment groups are fundamentally incomparable, resulting in the positivity assumption being violated. Maybe it is necessary to go back to the definition of the study population and exclude specific types of patients who are always/never treated.

In an ideal world we would repeat this process until we have achieved covariate balance, before we move on to estimate the treatment effect. This would ensure that we have separated the design and analysis phase of the study, just as in a RCT. This is of course rarely what ends up happening in a real observational study, since there can be many different valid reasons for going back and changing something after the treatment effect has been estimated, but it is something that should be strived for nonetheless.

---

## Balance assessment

How can we assess the covariate balance?

- "Table 1" of weighted/matched population 

- Look at $ps$ distribution after weighting/matching

- Standardized differences

- Look at weights

- Empirical CDF

We are assuming balance of the multivariate distribution of confounders. Assess balance in strata of confounders!

???

So how do we assess the balance of our confounders? This can be done in many ways, some more informative than others. We will look at some of the common approaches. 

Note that we are assuming that the *multivariate* distribution of covariates are balanced, ie there should not only be balance in the marginal distribution of each separate covariate, but the multivariate distribution of $X$ should be balanced, ie there should be balance in all strata defined by the covariates included in $X$. This is infeasible to do in practice most of the time, but you should at least make some random checks.

---

## Table 1

- Highly subjective

- Only compares eg N (%) or median (Q1-Q3) of distributions, not higher moments. Insufficient for continuous variables.

- Can be used to get a quick overview of the matched/weighted population.

- Testing balance with p-values is not good.

???

The most common way to assess covariate balance is to make a "Table 1" of the matched/weighted population and compare eg N (%) or median (Q1-Q3) of distributions. This is a highly subjective way of assessing balance, and for continuous variables it is also not enough, as higher moments of the distribution like the variance also needs to be balanced.

That being said, we usually make a summary table anyway, since it is common to include the weighted/matched summary table when reporting the analysis, and the table can be used as a quick way to assess if something is very wrong with the matched/weighted populations.

Testing balance of covariates using p-values is also not great. p-values are heavily affected by sample size, and everything will be "significantly imbalanced" if you have a large population.

---

## Table 1

```{r summary-tbl}

summary_tbl %>%
  gt(rowname_col = "label") %>%
  tab_spanner("Original", vars(pop_0, pop_1)) %>%
  tab_spanner("ATE-weighted", vars(ate_0, ate_1)) %>%
  tab_spanner("ATT-weighted", vars(att_0, att_1)) %>%
  tab_spanner("Matched", vars(matched_0, matched_1)) %>%
  cols_label(
    ate_0 = "Untreated",
    att_0 = "Unteated",
    matched_0 = "Untreated",
    pop_0 = "Untreated",
    pop_1 = "Treated",
    ate_1 = "Treated",
    att_1 = "Treated",
    matched_1 = "Treated"
  ) %>%
  # xaringan and gt css rules are clashing, so until this is fixed we need
  # to use tab_style to control font size. Furthermore, giving multiple
  # locations at once in a list does not work for some reason...
  tab_style(cell_text(size = "60%"), cells_body()) %>% 
  tab_style(cell_text(size = "60%"), cells_column_labels(everything())) %>% 
  tab_style(cell_text(size = "60%"), cells_column_spanners(everything())) %>% 
  tab_style(cell_text(size = "60%"), cells_stub()) 

```

???

Not easy to absorb all the information in this table. Lets make a graphical visualization instead.

---

## Graph 1

```{r summary-graph}

dat0 <- analysis_dat %>%
  select(-c("id", "time", "death", "ps", "match")) %>%
  mutate(
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated")),
    pop = factor(pop),
    risk_score = factor(risk_score),
    comorbidity_score = factor(
      comorbidity_score, 
      c("0", "1-2", "3+"), 
      c("0", "1-2", "3+")
    ),
    male = factor(male, c(0, 1), c("Female", "Male")),
    pop_treat = factor(paste0(pop, ": ", treatment))
  )

dat1 <- dat0 %>%
  group_by(pop_treat) %>%
  summarize("n_pt" = sum(w), .groups = "keep") %>%
  right_join(dat0, by= c("pop_treat")) %>%
  mutate(
    pop_treat = factor(paste0(pop_treat, " (n = ", formatC(n_pt, format = "f", digits = 0, big.mar = ","), ")"))
  )

# Ridgeline plot of risk score

# Weighted ridgeline plots not implemented in ggridges, but if stat_density
# is used instead of stat_density_ridges it is possible to make a weighted plot
# although things like quartile lines is not possible.
age_plot <- dat1 %>%
  ggplot(aes(x = age, y = pop, fill = treatment)) +
  geom_density_ridges(
    aes(height = ..density.., weight = w), 
    alpha = 0.5,
    stat="density",
    scale = 1
  ) +
  theme_ridges(grid = FALSE) + 
  scale_x_continuous(expand = c(0, 0.05), breaks = c(-2, 0, 2)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_manual(values = cvd_colours) +
  labs(x = NULL, y = NULL, fill = NULL, title = "Age") +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5, face = "plain"),
    legend.position = "bottom",
    legend.justification = "center",
    legend.title = element_text(size = 10),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.x = element_line(),
    axis.text.x = element_text(size = 8, colour = "black"),
    legend.text = element_text(size = 8)
  )

# Percent stacked barchart of sex 
sex_plot <- dat1 %>%
  ggplot(aes(y = pop_treat, fill = male, weight = w)) +
  geom_bar(position = "fill") +
  geom_hline(yintercept = 2.5) +
  geom_hline(yintercept = 4.5) +
  geom_hline(yintercept = 6.5) +
  scale_x_continuous(expand = c(0, 0.05), labels = scales::percent) +
  scale_fill_manual(
    values = c("#F7A8B8", "#55cdfc"),
    guide = guide_legend(reverse = TRUE)
  ) +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(x = NULL, fill = NULL, title = "Sex") + 
  theme_bw() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    panel.grid = element_blank(),
    panel.border = element_blank(),
    axis.title = element_blank(),
    axis.text.y = element_text(hjust = 0, size = 10, colour = "black"),
    axis.ticks.y = element_blank(),
    axis.line.y = element_blank(),
    axis.text.x = element_text(size = 8, colour = "black"),
    axis.line.x = element_line(),
    legend.position = "bottom",
    legend.justification = "center",
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10)
  )


# Percent stacked barchart of comorbidity_score
comorbidity_score_plot <- dat1 %>%
  ggplot(aes(y = pop_treat, fill = comorbidity_score, weight = w)) +
  geom_bar(position = position_fill(reverse = TRUE)) +
  geom_hline(yintercept = 2.5) +
  geom_hline(yintercept = 4.5) +
  geom_hline(yintercept = 6.5) +
  scale_x_continuous(expand = c(0, 0.05), labels = scales::percent) +
  scale_fill_brewer(
    # labels = c("+3", "1-2", "0"), 
    palette = "Greens"
    # direction = -1, 
    # guide = guide_legend(reverse = TRUE)
  ) +
  labs(x = NULL, fill = NULL, title = "Comorbidity score") + 
  theme_bw() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    panel.grid = element_blank(),
    panel.border = element_blank(),
    axis.title = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.y = element_blank(),
    axis.text.x = element_text(size = 8, colour = "black"),
    axis.line.x = element_line(),
    legend.position = "bottom",
    legend.justification = "center",
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10),
  )

# Percent stacked barchart of risk_score
risk_score_plot <- dat1 %>%
  ggplot(aes(y = pop_treat, fill = risk_score, weight = w)) +
  geom_bar(position = position_fill(reverse = TRUE)) +
  geom_hline(yintercept = 2.5) +
  geom_hline(yintercept = 4.5) +
  geom_hline(yintercept = 6.5) +
  scale_x_continuous(expand = c(0, 0.05), labels = scales::percent) +
  labs(x = NULL, fill = NULL, title = "Risk score") + 
  theme_bw() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    panel.grid = element_blank(),
    panel.border = element_blank(),
    axis.title = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.y = element_blank(),
    axis.text.x = element_text(size = 8, colour = "black"),
    axis.line.x = element_line(),
    legend.position = "bottom",
    legend.justification = "center",
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10),
  )

(sex_plot | risk_score_plot | age_plot | comorbidity_score_plot) & theme_trans

```

???

First and foremost, we can see that in the matched population we have the same number of treated and untreated patients, and that we have dropped a few treated patients from the original population. In the ATT-weighted population the number of untreated patients have been reweighted to be more similar to the number of treated patients, and in the ATE-weighted population both treatment groups have been reweighted to have approximately the size of the whole population. This is all as expected per our earlier observations on how PS matching and PS weighting works. 

We can see that there is a large imbalance in the sex distribution in the original population, but that there seems to be balance after matching and weighting. Note how the sex distribution shifts to reflect the distribution in the target distribution, eg the distribution among the treated for matching and ATT weighting, and the overall population for ATE weighting. 

We can see that the distribution of the risk score is very similar in the original population, which reinforce our belief that it is not a true confounder but a risk factor. Because of this the distribution is mostly unchanged after matching and weighting, as expected.

This graphical visualization also gives us the opportunity to plot the entire distribution of age. As with the sex covariate, we can see that the distribution is more balanced after matching and weighting.

The same conclusions holds for the comorbidity score.

Overall, the marginal balance of the confounders looks very good, but we should do additional assessments.

---

## ps distribution

- Quickly assess if something is very wrong with PS model

- Identical $ps$ distributions $\neq$ identical covariate distributions.

- Not a good way to assess covariate balance

???

Another popular way to assess covariate balance is to compare the $ps$ distribution of treated and untreated patients after matching/weighting.

We can use this to quickly check that we haven't done something horribly wrong in our matching/weighting, but identical $ps$ distributions does not equal identical covariate distributions, so as we are not directly assessing covariate balance, this plot does not tell us much.

---

## ps distribution

```{r ps-dist}

dat1 <- analysis_dat %>%
  mutate(
    pop = factor(
      pop,
      c("Original", "Matched", "ATE-weighted", "ATT-weighted"),
      c("Original", "Matched", "ATE-weighted", "ATT-weighted")
    ),
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated"))
  )

dat1 %>%
  ggplot(aes(ps, fill = treatment, group = treatment, weight = w)) +
    geom_density(alpha = 0.5, bw = 0.01) +
    facet_wrap(~pop) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    labs(
      title = NULL,
      fill = NULL,
      group = NULL,
      y = NULL
    ) +
    scale_fill_manual(values = cvd_colours) +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.text.y = element_blank(),
      legend.position = c(0.6, 0.9),
      panel.spacing = unit(1.5, "lines")
    ) +
    theme_trans +
    coord_cartesian(xlim = c(-0.05, 1.05))

```

???

We see that matching and weighting has worked as intended. In the matched population the untreated population now has a ps-distribution that is nearly identical to the ps-distribution of the treated.

We also see that that for both weighted populations, the ps-distributions have been successfully reweighted to be very similar to the target population.

Based on this we should not conclude that PS matching has removed confounding entirely, but that there is residual confounding in the weighted populations. As we shall see this is not the case, and this is why we should not draw conclusions from these type of plots.

---

## Standardized differences 

$$SD = \frac{|\bar{x}_t - \bar{x}_c|}{\sqrt{\frac{s^2_t + s^2_c}{2}}}$$

where

$$\bar{x} = \frac{1}{\sum_i w_i} \sum_i w_i x_i$$

$$s^2 = \frac{\sum_i w_i}{(\sum_i w_i)^2 - \sum_i w_i^2}\sum_i w_i (x_i -  \bar{x})^2$$

- Not influenced by sample size

- Can be used for both continuous and dichotomous variables

- Categorical variables?

- Could also include SD for higher-order moments of continuous variables

???

We have talked about what we should not do. Now lets talk about what we *should* do.

A less subjective way to assess covariate balance is by calculating the  standardized difference (SD) for each covariate.

The definition of SD can vary slightly, here we take the absolute value of the numerator, and we don't multiply by 100. SD < 0.1 is generally considered to indicate that there is sufficient covariate balance.

For unweighted populations the formulas reduces to the standard formulas.

The SD is appropriate to calculate for both continuous and dichotomous variables. One approach to handle categorical variables is by replacing them with a set of dichotomous variables and then calculate the SD for each of those.

You could also calculate the SD for higher-order moments of a continuous variable, eg the square of the variable for assessing balance of variance. We will omit this in our example, but it is one way to do a more proper assessment of balance of continuous variables, where it is insufficient with balance in the mean of the distribution.

---

## Standardized differences

```{r sd-graph}

dat1 <- standardized_differences %>%
  mutate(
    strata_male = factor(
      strata_male,  
      c("Overall", "Female", "Male"), 
      c("Overall", "Female", "Male")),
    pop = factor(
      pop,
      c("Original", "Matched", "ATE-weighted", "ATT-weighted"),
      c("Original", "Matched", "ATE-weighted", "ATT-weighted")
    ),
    var = factor(
      var,
      c("male", "risk_score", "age", "comorbidity_score: 0", "comorbidity_score: 1-2", "comorbidity_score: 3+"),
     c("Male", "Risk score", "Age", "Comorbidity score: 0", "Comorbidity score: 1-2", "Comorbidity score: 3+")
    )
  )

dat1 %>%
  ggplot(aes(sd, var, group = pop, colour = pop, shape = pop)) +
  geom_point() +
  geom_vline(xintercept = 0.1, linetype = "dashed") +
  facet_wrap(~strata_male) +
  theme_bw() +
  scale_colour_manual(values = cvd_colours) +
  labs(
    x = "Standardized difference",
    y = NULL,
    group = NULL,
    colour = NULL,
    shape = NULL
  ) +
  theme(
    legend.position = "bottom",
    panel.grid = element_blank(),
  ) +
  theme_trans

```

???

We can se that the SD is very small after matching or weighting in both the overall population, and if we stratify by sex. We see no indication of lack of covariate balance based on this assessment.

---

## Weight statistics

- If PS weighting is used, look at weights

- Large weights only problematic if large relative to the population size:

 - Max weight = 10, N = 1 million: Irrelevant
 - Max weight = 10, N = 100: Not good!

???

If we are using PS weighting we should look at the weights. This is not a direct assessment of covariate balance but large weights indicate problems with the positivity assumption and is a sign that the balance could be improved.

Large weights are only problematic is they are large relative to the population size. If we have a weight of 10 in a population of 1 million we do not care, but a weight of 10 in a population of 100 would probably be very problematic.

---

## Weight distribution

```{r weight-stats}

weight_stats %>% 
  filter(pop %in% c("ATE-weighted", "ATT-weighted")) %>%
  mutate(
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated"))
  ) %>%
  gt()
  
```

???

We see that relative to population sizes, the maximum weights are not that large and there are not that many "large" weights based on the percentiles, so there is no cause for concern here.

---

## Empirical CDF

- Continuous confounder: balance in mean is not enough.

- Empirical CDFs are a straight forward way to compare the entire distribution of continuous variables.

$$CDF(x) = \frac{1}{\sum_i w_i} \sum w_i I(x_i \leq x)$$

where $w_i$ is the weight and $I$ the indicator function.

???

For a continuous variable it is not enough to compare means of distributions using SD's. We need to balance all moments of the distribution, eg the variance. One way to compare the entire distribution of continuous variables is by comparing the empirical CDF.

---

## Empirical CDF

```{r empirical-cdf}

empirical_cdf %>%
  mutate(
    pop = factor(
      pop, 
      c("Original", "Matched", "ATT-weighted", "ATE-weighted"), 
      c("Original", "Matched", "ATT-weighted", "ATE-weighted") 
    ),
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated")),
    strata_male = factor(
      strata_male,
      c("Overall", "Female", "Male"),
      c("Overall", "Female", "Male")
    )
  ) %>%
  ggplot(aes(x, cdf, group = treatment, colour = treatment)) +
  geom_step() +
  labs(
    x = "Age",
    y = "CDF",
    group = NULL,
    colour = NULL
  ) +
  facet_grid(vars(pop), vars(strata_male)) +
  theme_bw() +
  scale_colour_manual(values = cvd_colours) +
  theme(panel.grid = element_blank()) +
  theme_trans

```

???

Everything look balanced, also in strata of sex. 

Based on these assessments we are satisfied with the covariate balance we have attained. If we were not, we would go back and eg fine-tune the PS model and then redo the balance assessments until we were.

---

## Variance / confidence interval estimation

- Usual variance estimates assumes independent observations

- After matching/weighting, observations are no longer independent

- Usual formulas will result in incorrect CI coverage probabilities

- Often overlooked complication

???

We are not only interested in an estimate of the treatment effect, but also in some measure of precision of the estimate, usually a 95% confidence interval. Standard variance estimates assumes independent observations, but in our weighted/matched population, this is not the case! In weighted populations we include multiple copies of the same patients, and in matched populations the observations are "more alike" than in the "general population", vaguely speaking.

If we do not take this lack of independence into account, our estimated CI's are not going to have the correct coverage probabilities.

This complication is often overlooked/ignored. In some cases, proper/improper CI estimates will be indistinguishable from each other, but sometimes, especially when using PS weighting, there will be noticeable differences. So it is not something that should be ignored because "it does not matter in practice".

There is some controversy about whether or not observations are independent when doing PS matching without replacement, but several simulation studies show that it is not the case, and that this lack of independence results in improper CI coverage if it is not taken into account.

Without going into much detail, We will here suggest two standard approaches to handle variance/CI estimation. How to implement this in SAS is shown in the accompanying SAS example.

---

## The robust sandwich estimator

Adjustment of variance estimates from regression models

Pros:

- Easy to specify when fitting GLM's / Cox models in SAS (and R?)

Cons:

- Only applicable when sample statistic of interest is a regression parameter

- Very time-consuming for large populations

- Assumes true PS's used. Still results in improper CI coverage probability.

???

The so-called robust sandwich estimator is an adjustment of the variance estimates from a regression model. It is easy to specify that this adjustment should be made when fitting GLM's and Cox models, at least in SAS. On the other hand, the method is only applicable when the sample statistic of interest is a regression parameter. Also, it can be very time-consuming to estimate the sandwich estimator for large populations, and the approach assumes that the true PS have been used, so the estimated CI's will still have improper coverage probabilities.

The sandwich estimator is the usual go-to solution when the sample statistic of interest is a regression parameter. It is an easy and usually fast approach. And while it is technically not a perfect solution to our problem because we don't use the true ps's, the estimated CI's have approximately the correct coverage.

---

## Non-parametric Bootstrapping

Resample method used to estimate the distribution of any sample statistic.

Pros:

- Can be used when analytic form of sample statistic distribution is unknown / complicated

- Can be used on **any** sample statistic, not only regression coefficients.

Cons:

- Often infeasible in practice.

- Can be done in many variations of increasing complexity. What is the best approach?

- Too good to be true? Relies on additional assumptions!

???

A more general approach is to use non-parametric bootstrapping to estimate the distribution of the sample statistic of interest by resampling the population with replacement many times, and calculating the estimate of the sample statistic in each sample. The resample estimates will give an estimate of the entire distribution of the sample statistic, and we can use that to construct a CI using eg the percentiles of the distribution.

This approach can be used to estimate CI's for whatever sample statistic we are interested in, which is a big advantage when the analytic form of the distribution of the sample statistic is unknown or very complicated.

On the other hand, bootstrapping can be very time-consuming since many resamples are needed for a good estimate (probably at least 100 for a 95% CI). This quickly becomes problematic when many analyses have to be done, the population is very big and/or analyses takes a long time to run in the first place. Furthermore, the percentile method mentioned here is the simplest, but not necessarily the best approach. A ton of variations of increasing complexity can be used to construct estimates of variances, CI's etc, and more sophisticated methods might be necessary to ensure reasonable estimates.

Finally, bootstrapping seems too good to be true. How is it even possible to estimate the distribution of the sample statistic from only the sample itself? By making additional assumptions! Talking about these assumptions is out of scope of this presentation, but it is important to realize that we are making additional assumptions that we should be aware of!

---

## Bootstrap example - sample mean

Let $x_1, \dots, x_n \sim N(\mu, \sigma^2)$. We want to estimate  $CI_{95\%}(\mu)$

Analytic approach:

$$x_1, \dots, x_n \sim N(\mu, \sigma^2) \quad \Rightarrow \quad \mu \leftarrow \bar{x} \sim N(\mu, \frac{\sigma^2}{n})$$

$$CI_{95\%}(\mu) \approx [\bar{x}-1.96\frac{S}{\sqrt{n}}, \bar{x}+1.96\frac{S}{\sqrt{n}}]$$

Bootstrap approach:

1. Resample, with replacement, population from $x_1, \dots, x_n$ $M$ times

2. Calculate $\bar{x_m}$ for $m=1,\dots,M$.

3. Use percentiles of $\bar{x}_m, m=1,\dots,M$ to estimate $CI_{95\%}(\mu)$:

$$CI_{95\%}(\mu) \approx [\bar{x}_{p_{2.5}}, \bar{x}_{p_{97.5}}]$$

???

As said, an in-depth discussion of what additional assumptions we are making is out of scope of this presentation. But lets try out the method in a simple example to reassure ourselves that it actually looks like it works in practice.

Lets imagine we make $n$ independent draws from a normal distribution: $x_1, \dots, x_n \sim N(\mu, \sigma^2)$, and that we want to estimate the population mean, $\mu$, and a corresponding 95% CI. 

We know that $\mu \leftarrow \bar{x} \sim N(\mu, \frac{\sigma^2}{n})$, and it follows that $CI_{95\%}(\mu) \approx [\bar{x}-1.96\frac{S}{\sqrt{n}}, \bar{x}+1.96\frac{S}{\sqrt{n}}]$, ie we can find an analytical form for the CI we can estimate using our sample data.

Using the bootstrap approach we would instead make $M$ resamples of our original sample, calculate the sample mean in each resample, and then use these as an estimate of the distribution of the estimated sample mean. We can then rank the estimates and pick the 2.5 and 97.5 percentile estimates and use them as an estimate for the 95% CI of the population mean.

---

## Bootstrap example - sample mean

```{r bootstrap-setup}

n <- 1e3
m <- 1e2
set.seed(1)

x <- rnorm(n)
analytic_est_ci <- c(
  mean(x),
  mean(x) - 1.96 * sd(x) / sqrt(n),
  mean(x) + 1.96 * sd(x) / sqrt(n) 
)

dat <- data.table(x = x)
dat <-append(
    list(dat), 
    lapply(1:m, function(i) data.table(x = sample(dat$x, replace = TRUE)))
  ) 

dat <- rbindlist(dat, idcol = TRUE)

mean_est <- dat %>%
  group_by(.id) %>%
  summarize(mean = mean(x), .groups = "keep")

bootstrap_est_ci <- c(
  mean_est$mean[1], 
  quantile(mean_est$mean[-1], c(0.025, 0.975), names = FALSE)
)

```

Let $\mu = 0$, $\sigma = 1$, $n =$ `r n` and $M =$ `r m`:

<span style="color: green;">analytic: $CI_{95\%}(\mu)=[\bar{x}-1.96\frac{S}{\sqrt{n}}; \bar{x}+1.96\frac{S}{\sqrt{n}}] =$ `r glue("[",round(analytic_est_ci[2], 3),";",round(analytic_est_ci[3], 3),"]")`
</span>

<span style="color: red;">bootstrap:
$CI_{95\%}(\mu)=$ `r glue("[",round(bootstrap_est_ci[2], 3),";",round(bootstrap_est_ci[3], 3),"]")`
</span> 

```{r bootstrap-graph, fig.width = 9, fig.height = 3}
mean_est %>%
  filter(!.id == 1) %>%
  ggplot(aes(mean)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.002, colour = "black", fill = "lightblue") +
  geom_density(aes(y = ..density..)) +
  geom_vline(aes(xintercept = analytic_est_ci[2]), colour = "green", linetype = "dotted") +
  geom_vline(aes(xintercept = analytic_est_ci[3]), colour = "green", linetype = "dotted") +
  geom_vline(aes(xintercept = bootstrap_est_ci[2]), colour = "red", linetype = "dashed") +
  geom_vline(aes(xintercept = bootstrap_est_ci[3]), colour = "red", linetype = "dashed") +
  theme_classic() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_trans +
  labs(x = expression(bar(x)[m])) 
```

???

Let say that $\mu = 0$, $\sigma = 1$, $n =$ `r n` and $M =$ `r m`. Following the steps from the previous slide we can see that our estimate of the sample mean distribution is very rough, but despite this we still get essentially identical CI estimates from the bootstrap and analytic approach. So the bootstrap approach seems to work, at least in this example.

---

## Assess proportional hazards assumption

```{r assess-cox-ph}

assess_ph %>%
  mutate(
    pop = factor(
      pop, 
      c("Original", "Matched", "ATT-weighted", "ATE-weighted"), 
      c("Original", "Matched", "ATT-weighted", "ATE-weighted") 
    ),
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated")),
  ) %>%
  ggplot(aes(log_time, lml_surv, colour = treatment)) +
  geom_step() +
  facet_wrap(~pop) +
  labs(
    x = "log(Days since diagnosis)",
    y = "log(-log(Survival))",
    colour = NULL
  ) +
  theme_bw() +
  theme(
    panel.grid = element_blank()
  ) +
  theme_trans

```

???

Before fitting any Cox regression models we should first assess if the PH assumption is fulfilled. This can be done in many ways, but a common simple approach is to plot log(-(log(survival) vs log(time) for treated and untreated patients separately, and check that the transformed survival curves are approximately parallel. In this case, we conclude that we do not see evidence of a violation of the PH assumption. The non-proportional part of the graph is restricted to the first "few" days of follow-up where few outcomes have had a chance to happen, as is also often seen in real studies. In this specific case, we actually **know** that the PH assumption is fulfilled, since the data was simulated so that this was the case.

Note that this type of PH assessment is also commonly done for conditional Cox models. In a conditional model the PH assumption needs to be fulfilled in **all** strata of confounders, not just the marginal treatment strata. Despite of this, it is common to just check the marginal treatment strata, since checking all strata is usually infeasible in practice. So in the case of a conditional model, this type of assessment is less than ideal most of the time, whereas for a marginal model it is more justifiable.

---

## Relative treatment effect

```{r relative-effect-estimates}

relative_effect_estimates %>%
  filter(effect == "Marginal" & !pop == "Original") %>%
  select(c("pop", "var_est",  "hr_ci")) %>%
  pivot_wider(names_from = var_est, values_from = hr_ci) %>%
  gt() %>%
  cols_label(pop = "Population", bootstrap = "Bootstrap CI", sandwich = "Sandwich CI") %>%
  tab_spanner("HR (95% CI)", columns = vars(bootstrap, sandwich))

cond_effect <- relative_effect_estimates %>%
  filter(effect == "Conditional" & pop == "Original") %>%
  select(hr_ci) %>% pull()

ate_effect <- relative_effect_estimates %>%
  filter(effect == "Marginal" & pop == "ATE-weighted" & var_est == "bootstrap") %>%
  select(HazardRatio) %>% pull()

att_effect <- relative_effect_estimates %>%
  filter(effect == "Marginal" & pop == "ATT-weighted" & var_est == "bootstrap") %>%
  select(HazardRatio) %>% pull()
```

<br><br>Conditional treatment effect estimate: `r cond_effect`

???

Finally we are at the point where we actually estimate the treatment effect! We start by estimating the relative ATE/ATT as defined earlier, ie as a marginal hazard ratio of all-cause-mortality for treatment versus no treatment. As discussed earlier, we will do this by fitting a Cox model where only the treatment indicator is included as a covariate in the matched/weighted population. Furthermore, if we are doing PS weighting, we provide the statistical software with the patient weights as well.

In this hypothetical study, we see that the relative ATE and ATT (ATT weighting and matching) estimates are almost identical. Actually, the true ATE and ATT *are* identical in the simulated data, and the estimates are very close to the true effect, so it would seem like all the methods are performing equally well, at least in this specific example. Furthermore, we can see that both the robust sandwich estimator and the bootstrap approach resulted in very similar CI's, and all CI's include the true effect.

To iterate what was discussed earlier: the ATE and ATT does **not** generally coincide in real observational studies! It is purely due to a lack of sophistication in the simulated data that it is the case in this specific example.

Finally, it is also worth noting that had we estimated the conditional treatment effect, ie fitted a Cox regression on the original population including not only the treatment indicator, but also all the confounders as covariates in the model, we would get a conditional treatment effect estimate of `r cond_effect`. These estimates are clearly different and this is because the conditional and marginal treatment effect does not coincide when the effect estimator is non-collapsible as mentioned earlier. As with the marginal effect estimates, the conditional effect estimate is very close to the true effect, and the true effect is included in the CI.

---

## Marginal cumulative incidence curves

```{r cum-inc-curves}
dat1 <- cumulative_incidences %>%
  mutate(
    treatment = factor(treatment, c(0, 1), c("Untreated", "Treated"))
  )

dat1 %>%
  ggplot(aes(time, cum_inc, group = treatment, colour = treatment)) +
  geom_step() +
  theme_classic() +
  scale_colour_manual(values = cvd_colours) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(
    x = "Days since diagnosis",
    y = "Mortality risk",
    group = NULL,
    colour = NULL
  ) +
  facet_wrap(~pop) +
  theme_bw() +
  theme(
    legend.position = c(0.1, 0.9),
    panel.grid = element_blank()
  ) +
  theme_trans
```

???

Next, we want to estimate the absolute ATE/ATT. As defined earlier, the absolute ATE is the risk difference at some time point, in this case the 1-year risk difference. We estimate the risk difference by estimating the marginal cumulative incidence one year after diagnosis for both treated and untreated patients and subtracting the estimates. In this case we decide it is too much of a hassle to figure out an analytic formula for the CI, so we decide to only use the bootstrapping approach. Again, we do this by resampling the population and estimating the risk difference in each resample, then use percentiles of the risk difference estimates to form a CI.

In this graph the marginal cumulative incidence curves for treated and untreated patients are plotted in each population. These are also valuable on their own, as they provide estimates of the risk of all-cause mortality had everyone been treated or not treated.

---

## Absolute treatment effect

```{r absolute-estimate-effect}

absolute_effect_estimates %>%
  filter(time == 365 & !pop == "Original") %>%
  mutate(
    diff_ci = paste0(
      round(cum_inc_diff, 3),
      " (",
      round(lcl, 3),
      ";",
      round(ucl, 3),
      ")"
    )
  ) %>%
  select(c("pop", "diff_ci")) %>%
  gt() %>%
  cols_label(pop = "Population", diff_ci = "Risk difference (95% CI)")

```

???

Again the estimates are very close to the true absolute effects, and this time we see a clear difference in the ATE and ATT estimates, because in this case the true ATE and ATT does not coincide.

---

## PS matching pros and cons 

Pros:

- Easy to analyze

- People are familiar with matching

Cons:

- Non-trivial to make matched population

- Very time-consuming relative to PS weighting

- Less clear how to estimate ATE

- Need 5:1 ratio of untreated to treated patients?

- Discards non-matched untreated patients

???

We have now concluded our analyses, and we can reflect on the strengths and weaknesses of propensity score matching and weighting.

A big advantage of PS-matching is, that after the matched population has been created it is easy to analyze, since we don't need to adjust for confounding and we don't have any ps-weights we need to be able to handle in our statistical analysis.

Another advantage is that people are typically familiar and comfortable with matched analyses, so it is easy to communicate the results of the analysis to readers and convince them of the validity of the analysis.

On the other hand, it is not trivial at all to make the matched population. There are many different matching designs that can be used, and in this presentation we have only touched on one reasonable way to do it. Furthermore, implementations of PS matching seems to be rare in statistical software, so the matching process is often done manually. This often lead to very inefficient implementations that can make the matching process infeasible in practice. In any case, PS matching is very time-consuming relative to PS weighting.

Usually 1:1 matching of untreated to treated patients is done, and this leads to an ATT estimate. But matching can be done in different ways which leads to different casual contrasts. You could match treated to untreated patients to estimate the average effect in the untreated (ATU). You could also estimate the ATE by eg finding matches for all patients, matching untreated to treated patients and treated patients to untreated patients. But other matching techniques also exists that leads to the ATE being estimated.

The conventional wisdom is that the ratio of untreated to treated patients need to be high, eg 5:1. While this is indeed necessary if matching is done without replacement to avoid depleting the pool of untreated patients we can match from, it is not necessarily of any importance when matching is done with replacement. As we have seen in the example where there are 50% treated patients, there is nothing inherently wrong with matching with replacement. It works just fine, and makes it possible to do ps-matching even when the ratio of untreated to treated patients is low. The reason why many people prefer matching without replacement is probably because this is what has been done historically.

Finally, when doing PS matching we are discarding all non-matched untreated patients from our analysis. This can lead to a loss of precision in our estimates. We did not see this in our example, since we matched we had 50% treated patients and matched with replacement, so our matched population was approximately the same size.  

---

## PS weighting pros and cons

Pros:

- Straightforward to calculate weights to estimate eg ATT and ATE

- Efficient compared to making matched population

Cons:

- Software / methodology might not support weights!

- Dealing with extreme weights

???

Compared to PS matching it is very simple to calculate weights that leads to estimates of different causal contrasts of interest, eg the ATT and ATE.

It is also way more efficient to calculate weights than creating a matched population.

On the other hand, there are no guaranties that the used statistical software implementation of a statistical method or the methodology itself support weighted populations. So if PS weighting is to be used, it is critical to investigate whether the needed statistical analyses can be performed before committing to this method!

It is also not unlikely to have extreme weights that need to be handled one way or other. Other weighting approaches exists that are less prone to produce extreme weights, but in practice it is not always easy to solve this problem.

---

## Positivity assumption problems

Signs of violation:

- Exclusion of treated patients in matched population 

- Extreme weights in weighted population

- Lack of covariate balance

Possible solutions:

- Refine PS model

- Restrict study population

- Abandon PS analysis

What not to do:

- Ignore the problem

- Trim or truncate weights

???

We will end the presentation with some in-depth comments on the positivity assumption, since it is not always clear how this should be handled.

The positivity assumption states that each patient must have a non-zero probability of each treatment, ie for each patient we need to be able to find a similar patient who got the opposite treatment, so that we can use those patients to estimate what would have happened had the patient got the other treatment. It is not uncommon to have some degree of problem with this assumption.

If this assumption is violated it can manifest itself in different ways. If we do PS matching, we might not be able to find matches for all treated patients. With PS weighting we might have extremely large weights, because a patient's estimated PS is close to zero or one. In combination with one of the above, we might also notice that we can't achieve covariate balance.

So how do we solve this problem? Sometimes the problem is with the PS model. In a traditional outcome regression analysis, the conventional rule of thumb is that you need 10 outcomes for each confounder you want to adjust for. In a PS analysis we are fitting a PS model where the outcome is exposure, so the more confounders we want to include in the PS model, the more exposed patients we need. This can quickly become a problem when we have very few treated patients, and we want to include a large amount of confounders in our model. Before fitting any PS models, we should investigate how many treated patients we have, so we can assess if it is reasonable to fit the model we want to. Maybe we simply don't have enough data to support and ideal model, and a more parsimonious model has to be used.

In other cases the underlying problem is that some types of patients are (almost) always/never treated. In this case we should try to identify exactly what characteristics causes one to be always/never treated, and explicitly exclude such patients from our study population. We are not capable to infer anything meaningful for such patients, so we should explicitly exclude them, so that it is clear on what population we are making inference. 

If it is not possible to identify the problem, and/or you are unwilling to restrict the PS model / study population, then you are in the difficult position that your study question might be unanswerable with the data at hand, at least using PS methods. At this point the proper response is probably to try and figure out an alternative way to analyze the data.

So what should you not do? First of all you should not simply ignore the problem. It is not uncommon to see studies where PS matching is used, and a (large) proportion of treated patients has been removed from the matched population. It is then often argued that we are not interested in patients for whom we can't find matches anyway, so it is fine to just exclude them without any further thoughts, but this is problematic! If we do this, we are no longer estimating the ATT, but the ATT in a subgroup of patients based on a restriction on $ps$ values. No meaningful inference can come from such this approach. The correct interpretation of the estimated causal contrast would be something like "Among patients with diagnosis X, treated patients that did not have a too large or too small estimated probability of being treated had, on average, a 20% lower 1-year risk of Y than untreated patients". What does that even mean? It would be way better to figure out that, eg very old patients are causing the problems with the model, restrict the study population and then come to the conclusion that "Among patients younger than 120 with diagnosis X, treated patients had, on average, a 20% lower 1-year risk of Y than untreated patients".

It is also common to see $ps$ trimming and/or truncating being used with $PS$ weighting. Trimming entails removing patients with weights larger than some limit. This leads to the same problem as described in the previous paragraph. Another thing that is sometimes done is $ps$ truncation, where extreme weights are truncated to some upper limit. If we can obtain covariate balance without fiddling with the weights, it is likely irrelevant how "extreme" the weights are. Truncating the weights in this scenario might just result in worse covariate balance, without actually fixing a real problem. If we do have covariate imbalance, and weight truncation improves the situation, then maybe this solution is helpful. But as argued above, there is probably an underlying problem that should be fixed explicitly instead.

---

## Further reading

- More than two treatments`r cite_mod(title = "estimation for multiple treatments ")`

- Other PS weighting approaches `r cite_mod(title = "Alternative approaches for confounding adjustment")`

 
???

Some interesting topics did not make it into this presentation. Here is a list of topics with references for further reading.

---

## References

```{r refs, echo=FALSE, results="asis"}
# Use NoCite to add all references that are not cited to the bibliography
NoCite(my_bib, "*")
PrintBibliography(my_bib)
```
